# TorBoT
A python web crawler for Deep and Dark Web.

### Working Procedure/Basic Plan
The basic procedure executed by the web crawling algorithm takes a list of seed URLs as its input and repeatedly executes
the following steps:

1. Remove a URL from the URL list.
2. Download the corresponding page.
3. Check the Relevancy of the page.
4. Extract any links contained in it.
5. Add these links back to the URL list.
6. After all URLs are processed, return the most relevant page.

### Features
1. Crawls Tor links (.onion) only.
2. Returns Page title and address.
...(will be updated)

### Contribute
Contributions to this project are always welcome. 
To add a new feature fork this repository and give a pull request when your new feature is tested and complete.
The branch name should be your new feature name in the format <Feature_feature_name>. For example, <i>Feature_FasterCrawl_1.0</i>.
Contributor name will be updated to the below list. :D

## CREDITS

- [X] P5N4PPZ - PROJECT OWNER
